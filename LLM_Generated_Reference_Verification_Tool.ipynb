{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJUbVv9flTg/rOnGnxS8H1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xyshuai/LLM-generated-reference-checker/blob/main/LLM_Generated_Reference_Verification_Tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8D3_Wmh1qb7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "üìö LLM-Generated Reference Verification Tool - Interactive Version\n",
        "\n",
        "Usage:\n",
        "1. Run this cell\n",
        "2. Paste references into the text box (one per line)\n",
        "3. Click \"üöÄ Run Verification\" button\n",
        "4. View results with color highlighting\n",
        "\n",
        "‚úì Supports: APA, Chicago, Harvard, IEEE, ACM, MLA\n",
        "\n",
        "‚úì Primary API: OpenAlex (comprehensive, has retraction data)\n",
        "‚úì Fallback API: Crossref (broader coverage)\n",
        "\"\"\"\n",
        "\n",
        "# ================= Install dependencies (if needed) =================\n",
        "try:\n",
        "    import rapidfuzz\n",
        "except:\n",
        "    !pip install rapidfuzz -q\n",
        "\n",
        "import re\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from rapidfuzz import fuzz\n",
        "import string\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# ================= Configuration =================\n",
        "OPENALEX_BASE = \"https://api.openalex.org/works\"\n",
        "CROSSREF_BASE = \"https://api.crossref.org/works\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"ReferenceVerificationTool/1.0 (mailto:your_email@example.com)\",\n",
        "}\n",
        "\n",
        "TITLE_THRESHOLD = 85\n",
        "TITLE_MISMATCH_THRESHOLD = 70\n",
        "REQUEST_DELAY = 0.2\n",
        "\n",
        "\n",
        "# ================= Helper Functions =================\n",
        "\n",
        "def normalize_doi(doi):\n",
        "    \"\"\"Normalize DOI by removing URL prefix and trailing punctuation\"\"\"\n",
        "    if not doi:\n",
        "        return None\n",
        "    doi = re.sub(r'^https?://(dx\\.)?doi\\.org/', '', doi, flags=re.I)\n",
        "    doi = re.sub(r'^doi:', '', doi, flags=re.I)\n",
        "    doi = doi.rstrip('.,;)')\n",
        "    return doi.lower().strip()\n",
        "\n",
        "\n",
        "def extract_surname(author_name):\n",
        "    \"\"\"Extract surname from author name in various formats\"\"\"\n",
        "    if not author_name:\n",
        "        return \"\"\n",
        "\n",
        "    author_name = re.sub(r'\\(\\d{4}\\)', '', author_name).strip()\n",
        "    author_name = re.sub(r'^\\[\\d+\\]\\s*', '', author_name)\n",
        "\n",
        "    if ',' in author_name:\n",
        "        surname = author_name.split(',')[0].strip()\n",
        "        return surname.lower() if surname else \"\"\n",
        "\n",
        "    parts = author_name.split()\n",
        "    if not parts:\n",
        "        return \"\"\n",
        "\n",
        "    if len(parts) == 1:\n",
        "        return parts[0].lower()\n",
        "\n",
        "    last_part = parts[-1].replace('.', '').strip()\n",
        "    if len(last_part) <= 2 and (last_part.isupper() or len(last_part) == 1):\n",
        "        return parts[0].lower()\n",
        "    else:\n",
        "        return parts[-1].lower()\n",
        "\n",
        "\n",
        "def normalize_page_range(page_range):\n",
        "    \"\"\"Normalize page range to consistent format\"\"\"\n",
        "    if not page_range or page_range == \"-\":\n",
        "        return \"-\"\n",
        "    normalized = str(page_range).replace('‚Äì', '-').replace('‚Äî', '-').replace('‚àí', '-')\n",
        "    normalized = re.sub(r'\\s*-\\s*', '-', normalized)\n",
        "    return normalized.strip()\n",
        "\n",
        "\n",
        "def standardize_title(title):\n",
        "    \"\"\"Standardize title for comparison (lowercase, no punctuation)\"\"\"\n",
        "    if not title:\n",
        "        return \"\"\n",
        "    title = title.lower()\n",
        "    title = title.replace(\"u.k.\", \"uk\").replace(\"u.s.\", \"us\")\n",
        "    title = title.translate(str.maketrans('', '', string.punctuation))\n",
        "    title = re.sub(r'\\s+', ' ', title).strip()\n",
        "    return title\n",
        "\n",
        "\n",
        "# ================= Enhanced Reference Parser =================\n",
        "\n",
        "def parse_reference(raw_ref):\n",
        "\n",
        "    text = re.sub(r'^[\\[\\(\\{]?\\d+[\\]\\)\\}]\\.?\\s*', '', raw_ref.strip())\n",
        "\n",
        "    # ==================== DOI Extraction ====================\n",
        "    doi_match = re.search(\n",
        "        r'(?:https?://)?(?:doi\\.org/|DOI:?\\s*)?(10\\.\\d{4,9}/[^\\s\"\\'<>\\]]+)',\n",
        "        text, re.I\n",
        "    )\n",
        "    doi = doi_match.group(1).rstrip('.,;)]') if doi_match else None\n",
        "\n",
        "    # ==================== Year Extraction ====================\n",
        "    year = None\n",
        "    year_in_parentheses = False\n",
        "\n",
        "    # Try parentheses first (most common)\n",
        "    year_match = re.search(r'\\((\\d{4})[a-z]?\\)', text)\n",
        "    if year_match:\n",
        "        year = int(year_match.group(1))\n",
        "        year_in_parentheses = True\n",
        "    else:\n",
        "        # Try Chicago/MLA format: Author. 2012. Title (year after period without parentheses)\n",
        "        year_match = re.search(r'\\.\\s+(\\d{4})\\.\\s+[\\u201c\\u201d\"\\'A-Z]', text)\n",
        "        if year_match:\n",
        "            year = int(year_match.group(1))\n",
        "            year_in_parentheses = False\n",
        "        else:\n",
        "            # Try month-year format (IEEE: Sep. 2021)\n",
        "            year_match = re.search(r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\.?\\s+(\\d{4})', text, re.I)\n",
        "            if year_match:\n",
        "                year = int(year_match.group(1))\n",
        "            else:\n",
        "                # Try IEEE format: ..., Year. at the end or before doi\n",
        "                year_match = re.search(r',\\s*(\\d{4})\\.?\\s*(?:doi|$)', text, re.I)\n",
        "                if year_match:\n",
        "                    year = int(year_match.group(1))\n",
        "                else:\n",
        "                    # Last resort: any 4-digit year\n",
        "                    year_match = re.search(r'[,\\s](\\d{4})[;,\\.]', text)\n",
        "                    if year_match:\n",
        "                        year = int(year_match.group(1))\n",
        "\n",
        "    # ==================== Detect Format Type ====================\n",
        "    # Expanded IEEE detection: \"vol. X, no. Y\" OR \"Volume(Issue):Pages\" OR contains \"IEEE\"\n",
        "    is_ieee_style = bool(re.search(r'(?:vol\\.\\s*\\d+.*?no\\.\\s*\\d+|IEEE\\s+\\w+|\\d+\\(\\d+\\):\\d+)', text, re.I))\n",
        "    is_vancouver = bool(re.search(r';\\d+\\(\\d+\\):', text))\n",
        "    # Detect ALL quote types using Unicode\n",
        "    has_quotes = bool(re.search(r'[\\u201c\\u201d\\u2018\\u2019\"\\'\"]', text))\n",
        "\n",
        "    # ==================== Title Extraction ====================\n",
        "    title = \"Unknown\"\n",
        "\n",
        "    # Pattern 1: Quoted title (ALL Unicode quote types)\n",
        "    if has_quotes:\n",
        "        # Extract content between quotes (handle ALL Unicode quote types)\n",
        "        quote_patterns = [\n",
        "            r'\\u201c([^\\u201d]+)\\u201d',   # Smart double quotes \"\" (U+201C, U+201D)\n",
        "            r'\\u2018([^\\u2019]+)\\u2019',   # Smart single quotes '' (U+2018, U+2019)\n",
        "            r'\"([^\"]+)\"',                  # Standard double quotes \"\"\n",
        "            r\"'([^']+)'\",                  # Standard single quotes ''\n",
        "            r'[\\u201c\\u201d\"\\u2018\\u2019\\'](.+?)[\\u201c\\u201d\"\\u2018\\u2019\\']',  # Universal\n",
        "        ]\n",
        "        for pattern in quote_patterns:\n",
        "            quote_match = re.search(pattern, text)\n",
        "            if quote_match:\n",
        "                title = quote_match.group(1).strip()\n",
        "                break\n",
        "\n",
        "    # Pattern 2: IEEE format WITHOUT quotes\n",
        "    # Supports: \"vol. X, no. Y\" AND \"Volume(Issue):Pages\" AND \"IEEE Journal\"\n",
        "    if title == \"Unknown\" and is_ieee_style:\n",
        "        # Step 1: Find the position after last author (look for \" and [Name].\")\n",
        "        last_author_match = re.search(r'\\band\\s+[A-Z][\\w\\s\\.]+?\\.\\s+', text)\n",
        "\n",
        "        if last_author_match:\n",
        "            # Extract everything after \"and Author.\"\n",
        "            after_authors = text[last_author_match.end():]\n",
        "\n",
        "            # Step 2: Find title (text before journal name)\n",
        "            # Pattern A: Title. Journal, vol. X (traditional IEEE)\n",
        "            # Pattern B: Title. Journal, Volume(Issue):Pages (compact IEEE)\n",
        "            # Pattern C: Title. IEEE Journal (IEEE keyword)\n",
        "            title_patterns = [\n",
        "                r'^([A-Z][^\\.]+?)\\.\\s+[A-Z][\\w\\s&]+?,?\\s*vol\\.',      # Pattern A\n",
        "                r'^([A-Z][^\\.]+?)\\.\\s+[A-Z][\\w\\s&]+?,\\s*\\d+\\(',        # Pattern B\n",
        "                r'^([A-Z][^\\.]{20,}?)\\.\\s+IEEE',                       # Pattern C\n",
        "            ]\n",
        "\n",
        "            for pattern in title_patterns:\n",
        "                title_match = re.search(pattern, after_authors, re.I)\n",
        "                if title_match:\n",
        "                    title = title_match.group(1).strip()\n",
        "                    break\n",
        "\n",
        "        # Fallback: Look for long text before journal/IEEE keyword\n",
        "        if title == \"Unknown\":\n",
        "            # Match: After period, Capital start, 20+ chars, before IEEE or journal with volume\n",
        "            fallback_patterns = [\n",
        "                r'\\.\\s+([A-Z][a-z][\\w\\s:,\\-]{20,}?)\\.\\s+IEEE',\n",
        "                r'\\.\\s+([A-Z][a-z][\\w\\s:,\\-]{20,}?)\\.\\s+[A-Z][\\w\\s&]+?,\\s*\\d+\\(',\n",
        "                r'\\.\\s+([A-Z][a-z][\\w\\s:,\\-]{20,}?)\\.\\s+[A-Z][\\w\\s&]+?,?\\s*vol\\.',\n",
        "            ]\n",
        "\n",
        "            for pattern in fallback_patterns:\n",
        "                fallback_match = re.search(pattern, text, re.I)\n",
        "                if fallback_match:\n",
        "                    potential_title = fallback_match.group(1).strip()\n",
        "                    # Ensure it's not an author name (no \"LC Rodrigues\" pattern)\n",
        "                    if not re.search(r'\\b[A-Z]{1,3}\\s+[A-Z][a-z]+\\b', potential_title[:40]):\n",
        "                        title = potential_title\n",
        "                        break\n",
        "\n",
        "    # Pattern 3: Year WITHOUT parentheses (Chicago/MLA: Author. 2012. \"Title.\" or Author. 2012. Title.)\n",
        "    if title == \"Unknown\" and not year_in_parentheses and year:\n",
        "        # Pattern 3a: . Year. \"Title.\" Source (with quotes)\n",
        "        title_match = re.search(rf'\\.\\s+{year}\\.\\s+[\\u201c\\u201d\"\\'\"]?(.+?)[\\u201c\\u201d\"\\'\"]?[\\.?!]\\s+[A-Z]', text)\n",
        "        if title_match:\n",
        "            title = title_match.group(1).strip()\n",
        "        else:\n",
        "            # Pattern 3b: . Year. Title Source (no quotes, title ends before source)\n",
        "            title_match = re.search(rf'\\.\\s+{year}\\.\\s+(.+?)\\.\\s+[A-Z][A-Za-z\\s]+\\s+\\d+', text)\n",
        "            if title_match:\n",
        "                title = title_match.group(1).strip()\n",
        "\n",
        "    # Pattern 4: Year WITH parentheses (APA, Harvard: Author (2012). Title.)\n",
        "    if title == \"Unknown\" and year_in_parentheses:\n",
        "        patterns = [\n",
        "            # Pattern 4a: (Year). Title[.?!] Source\n",
        "            r'\\(\\d{4}\\)\\.\\s*(.+?)[\\.?!]\\s+[A-Z]',\n",
        "            # Pattern 4b: (Year) Title[.?!] Source (no period after year)\n",
        "            r'\\(\\d{4}\\)\\s+(.+?)[\\.?!]\\s+[A-Z]',\n",
        "            # Pattern 4c: Conference: (Year). Title. In Proceedings\n",
        "            r'\\(\\d{4}\\)\\s*\\.?\\s*(.+?)[\\.?!]\\s*(?:In\\s+)?(?:Proceedings?|Conference)',\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, text)\n",
        "            if match:\n",
        "                potential_title = match.group(1).strip()\n",
        "                if len(potential_title) > 10:\n",
        "                    title = potential_title\n",
        "                    break\n",
        "\n",
        "    # Pattern 5: Vancouver style: . Title. Source Year;\n",
        "    if title == \"Unknown\" and is_vancouver:\n",
        "        title_match = re.search(r'\\.(.+?)[\\.?!]\\s+[A-Z][^\\.]+\\s+\\d{4}', text)\n",
        "        if title_match:\n",
        "            title = title_match.group(1).strip()\n",
        "\n",
        "    # Clean title (remove ALL types of quotes using Unicode)\n",
        "    if title != \"Unknown\":\n",
        "        # Remove smart quotes (U+201C, U+201D, U+2018, U+2019)\n",
        "        title = title.replace('\\u201c', '').replace('\\u201d', '')  # \"\"\n",
        "        title = title.replace('\\u2018', '').replace('\\u2019', '')  # ''\n",
        "        # Remove standard quotes\n",
        "        title = title.replace('\"', '').replace(\"'\", '')\n",
        "        title = title.strip()\n",
        "\n",
        "    # ==================== Journal/Source Extraction ====================\n",
        "    journal = \"Unknown\"\n",
        "\n",
        "    if is_ieee_style:\n",
        "        # IEEE style: \"Title,\" Source, vol. X OR Title. Source, Volume(Issue)\n",
        "        if has_quotes:\n",
        "            # After closing quote (Unicode-aware split)\n",
        "            parts = re.split(r'[\\u201c\\u201d\\u2018\\u2019\"\\'\"]', text)\n",
        "            after_quote = parts[-1] if len(parts) > 1 else text\n",
        "            ieee_match = re.search(r',\\s*([^,]+?),\\s*(?:vol\\.|\\d+\\()', after_quote, re.I)\n",
        "            if ieee_match:\n",
        "                journal = ieee_match.group(1).strip()\n",
        "        else:\n",
        "            # Without quotes: Title. Journal, vol. OR Title. Journal, Volume(Issue)\n",
        "            ieee_patterns = [\n",
        "                r'\\.\\s+([A-Z][A-Za-z\\s&]+?),\\s*vol\\.',        # Pattern A\n",
        "                r'\\.\\s+([A-Z][A-Za-z\\s&]+?),\\s*\\d+\\(',         # Pattern B\n",
        "            ]\n",
        "            for pattern in ieee_patterns:\n",
        "                ieee_match = re.search(pattern, text, re.I)\n",
        "                if ieee_match:\n",
        "                    potential_journal = ieee_match.group(1).strip()\n",
        "                    # Make sure it's not the title (journal names are usually shorter)\n",
        "                    if len(potential_journal) < 100:\n",
        "                        journal = potential_journal\n",
        "                        break\n",
        "\n",
        "    elif is_vancouver:\n",
        "        vanc_match = re.search(r'\\.([^\\.]+)\\.\\s*\\d{4};', text)\n",
        "        if vanc_match:\n",
        "            journal = vanc_match.group(1).strip()\n",
        "\n",
        "    else:\n",
        "        # Standard formats\n",
        "        patterns = [\n",
        "            # Pattern 1: . Source, Volume or . \"Source\" Volume\n",
        "            r'[\\.?!]\\s*[\\u201c\\u201d\"\\'\"]?([A-Za-z\\s&]+?)[\\u201c\\u201d\"\\'\"]?\\s*,?\\s*\\d+\\s*\\(',\n",
        "            # Pattern 2: . Source Volume\n",
        "            r'[\\.?!]\\s+([A-Z][A-Za-z\\s&]+?)\\s+\\d+\\s*\\(',\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, text)\n",
        "            if match:\n",
        "                journal = match.group(1).strip()\n",
        "                break\n",
        "\n",
        "    # ==================== Volume/Issue/Pages ====================\n",
        "    volume, issue, page_range = \"-\", \"-\", \"-\"\n",
        "\n",
        "    # Pattern 1: vol. X, no. Y, pp. Z (IEEE traditional style)\n",
        "    if 'vol.' in text.lower():\n",
        "        vol_match = re.search(r'vol\\.\\s*(\\d+)', text, re.I)\n",
        "        issue_match = re.search(r'no\\.\\s*(\\d+)', text, re.I)\n",
        "        page_match = re.search(r'pp\\.\\s*([\\d‚Äì\\-‚Äî]+)', text, re.I)\n",
        "\n",
        "        if vol_match:\n",
        "            volume = vol_match.group(1)\n",
        "        if issue_match:\n",
        "            issue = issue_match.group(1)\n",
        "        if page_match:\n",
        "            page_range = normalize_page_range(page_match.group(1))\n",
        "\n",
        "    # Pattern 2: Volume(Issue): Pages or Volume(Issue), Pages (compact style)\n",
        "    if page_range == \"-\":\n",
        "        patterns = [\n",
        "            (r'(\\d+)\\s*\\((\\d+)\\):\\s*([\\d‚Äì\\-‚Äî]+)', True),  # Vol(Issue): Pages\n",
        "            (r',\\s*(\\d+)\\s*\\((\\d+)\\),\\s*([\\d‚Äì\\-‚Äî]+)', True),  # , Vol(Issue), Pages\n",
        "            (r'\\d{4};(\\d+)\\((\\d+)\\):([\\d‚Äì\\-‚Äî]+)', True),  # Year;Vol(Issue):Pages (Vancouver)\n",
        "            (r'\\s(\\d+)\\s*\\((\\d+)\\):\\s*([\\d‚Äì\\-‚Äî]+)', True),  # Space Vol (Issue): Pages\n",
        "            (r'\\s(\\d+):\\s*([\\d‚Äì\\-‚Äî]+)', False),  # Vol: Pages (no issue)\n",
        "        ]\n",
        "\n",
        "        for pattern, has_issue in patterns:\n",
        "            match = re.search(pattern, text)\n",
        "            if match:\n",
        "                if has_issue:\n",
        "                    volume, issue, page_range = match.groups()\n",
        "                else:\n",
        "                    volume = match.group(1)\n",
        "                    issue = \"-\"\n",
        "                    page_range = match.group(2)\n",
        "                page_range = normalize_page_range(page_range)\n",
        "                break\n",
        "\n",
        "    # Pattern 3: pp. X-Y (conference/book chapter)\n",
        "    if page_range == \"-\":\n",
        "        pp_match = re.search(r'pp\\.\\s*([\\d‚Äì\\-‚Äî]+)', text, re.I)\n",
        "        if pp_match:\n",
        "            page_range = normalize_page_range(pp_match.group(1))\n",
        "\n",
        "    # ==================== First Author ====================\n",
        "    if ',' in raw_ref:\n",
        "        first_author = raw_ref.split(',')[0].strip()\n",
        "    else:\n",
        "        if year:\n",
        "            if year_in_parentheses:\n",
        "                year_str = f\"({year})\"\n",
        "            else:\n",
        "                year_str = f\". {year}.\"\n",
        "\n",
        "            year_pos = raw_ref.find(year_str)\n",
        "            if year_pos > 0:\n",
        "                first_author = raw_ref[:year_pos].strip()\n",
        "            else:\n",
        "                first_author = raw_ref.split('.')[0].strip() if '.' in raw_ref else raw_ref.split()[0]\n",
        "        else:\n",
        "            first_author = raw_ref.split('.')[0].strip() if '.' in raw_ref else raw_ref.split()[0]\n",
        "\n",
        "    first_author = re.sub(r'^\\[\\d+\\]\\s*', '', first_author)\n",
        "    first_author = re.sub(r'\\(\\d{4}\\)', '', first_author).strip()\n",
        "    first_author = re.sub(r'\\.\\s*\\d{4}\\.', '', first_author).strip()\n",
        "\n",
        "    return {\n",
        "        \"raw_reference\": raw_ref,\n",
        "        \"ref_title\": title,\n",
        "        \"ref_first_author\": first_author,\n",
        "        \"ref_year\": year,\n",
        "        \"ref_journal\": journal,\n",
        "        \"ref_volume\": volume,\n",
        "        \"ref_issue\": issue,\n",
        "        \"ref_page_range\": page_range,\n",
        "        \"doi\": doi\n",
        "    }\n",
        "\n",
        "\n",
        "# ================= OpenAlex API Functions =================\n",
        "\n",
        "def query_openalex_by_doi(doi):\n",
        "    if not doi:\n",
        "        return None\n",
        "    try:\n",
        "        normalized = normalize_doi(doi)\n",
        "        url = f\"{OPENALEX_BASE}/doi:{normalized}\"\n",
        "        r = requests.get(url, headers=HEADERS, timeout=10)\n",
        "        return r.json() if r.status_code == 200 else None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ö†Ô∏è OpenAlex DOI lookup failed: {doi} - {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def query_openalex_by_title(title, max_results=10):\n",
        "    if not title or title == \"Unknown\":\n",
        "        return []\n",
        "    try:\n",
        "        t = title.lower()\n",
        "        t = re.sub(r'[&:?,;]', ' ', t)\n",
        "        t = re.sub(r'\\s+', ' ', t).strip()\n",
        "        words = t.split()\n",
        "        t_short = \" \".join(words[:8])\n",
        "\n",
        "        params = {\"filter\": f\"title.search:{t_short}\", \"per-page\": max_results}\n",
        "        r = requests.get(OPENALEX_BASE, headers=HEADERS, params=params, timeout=10)\n",
        "        if r.status_code == 200:\n",
        "            return r.json().get(\"results\", [])\n",
        "        return []\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ö†Ô∏è OpenAlex title search failed: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def extract_openalex_metadata(record):\n",
        "    authorships = record.get(\"authorships\", [])\n",
        "    full_author_list = \", \".join([a['author']['display_name'] for a in authorships]) or \"Unknown\"\n",
        "    first_author = authorships[0]['author']['display_name'] if authorships else \"Unknown\"\n",
        "\n",
        "    biblio = record.get(\"biblio\", {})\n",
        "    primary = record.get(\"primary_location\", {})\n",
        "\n",
        "    title = record.get(\"title\", \"Unknown\")\n",
        "    year = record.get(\"publication_year\", \"Unknown\")\n",
        "\n",
        "    source_name = \"Unknown\"\n",
        "    if primary.get(\"source\"):\n",
        "        source_name = primary[\"source\"].get(\"display_name\", \"Unknown\")\n",
        "    elif biblio.get(\"journal_name\"):\n",
        "        source_name = biblio.get(\"journal_name\")\n",
        "\n",
        "    volume = biblio.get(\"volume\") or \"-\"\n",
        "    issue = biblio.get(\"issue\") or \"-\"\n",
        "\n",
        "    first_page = biblio.get(\"first_page\")\n",
        "    last_page = biblio.get(\"last_page\")\n",
        "    if first_page and last_page:\n",
        "        page_range = f\"{first_page}-{last_page}\" if first_page != last_page else str(first_page)\n",
        "    else:\n",
        "        page_range = first_page or \"-\"\n",
        "\n",
        "    page_range = normalize_page_range(page_range)\n",
        "\n",
        "    raw_oa_doi = record.get(\"doi\")\n",
        "    if raw_oa_doi:\n",
        "        m = re.search(r'(10\\.\\d{4,9}/[^\\s\"\\'<>]+)', raw_oa_doi, re.I)\n",
        "        oa_doi_plain = m.group(1).rstrip('.,;)') if m else raw_oa_doi\n",
        "    else:\n",
        "        oa_doi_plain = None\n",
        "\n",
        "    is_retracted = record.get(\"is_retracted\", False)\n",
        "\n",
        "    doc_type_raw = record.get(\"type\", \"unknown\")\n",
        "    doc_type_map = {\n",
        "        \"article\": \"Journal Article\",\n",
        "        \"book-chapter\": \"Book Chapter\",\n",
        "        \"proceedings-article\": \"Conference Paper\",\n",
        "        \"posted-content\": \"Preprint\",\n",
        "        \"dataset\": \"Dataset\",\n",
        "        \"book\": \"Book\",\n",
        "        \"dissertation\": \"Dissertation\",\n",
        "        \"unknown\": \"Unknown\"\n",
        "    }\n",
        "    doc_type = doc_type_map.get(doc_type_raw, doc_type_raw.replace(\"-\", \" \").title())\n",
        "\n",
        "    return {\n",
        "        \"oa_full_author\": full_author_list,\n",
        "        \"oa_first_author\": first_author,\n",
        "        \"oa_title\": title,\n",
        "        \"oa_year\": year,\n",
        "        \"oa_journal\": source_name,\n",
        "        \"oa_volume\": volume,\n",
        "        \"oa_issue\": issue,\n",
        "        \"oa_page_range\": page_range,\n",
        "        \"openalex_id\": record.get(\"id\", \"Unknown\"),\n",
        "        \"oa_doi\": oa_doi_plain,\n",
        "        \"is_retracted\": is_retracted,\n",
        "        \"doc_type\": doc_type,\n",
        "        \"data_source\": \"OpenAlex\"\n",
        "    }\n",
        "\n",
        "\n",
        "def query_crossref_by_doi(doi):\n",
        "    if not doi:\n",
        "        return None\n",
        "    try:\n",
        "        normalized = normalize_doi(doi)\n",
        "        url = f\"{CROSSREF_BASE}/{normalized}\"\n",
        "        r = requests.get(url, headers=HEADERS, timeout=10)\n",
        "        if r.status_code == 200:\n",
        "            return r.json().get(\"message\")\n",
        "        return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ö†Ô∏è Crossref DOI lookup failed: {doi} - {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def query_crossref_by_title(title, max_results=5):\n",
        "    if not title or title == \"Unknown\":\n",
        "        return []\n",
        "    try:\n",
        "        params = {\"query.title\": title, \"rows\": max_results}\n",
        "        r = requests.get(CROSSREF_BASE, headers=HEADERS, params=params, timeout=10)\n",
        "        if r.status_code == 200:\n",
        "            return r.json().get(\"message\", {}).get(\"items\", [])\n",
        "        return []\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ö†Ô∏è Crossref title search failed: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def extract_crossref_metadata(record):\n",
        "    authors = record.get(\"author\", [])\n",
        "    if authors:\n",
        "        full_author_list = \", \".join([f\"{a.get('given', '')} {a.get('family', '')}\".strip() for a in authors])\n",
        "        first_author = f\"{authors[0].get('given', '')} {authors[0].get('family', '')}\".strip()\n",
        "    else:\n",
        "        full_author_list = \"Unknown\"\n",
        "        first_author = \"Unknown\"\n",
        "\n",
        "    title_list = record.get(\"title\", [])\n",
        "    title = title_list[0] if title_list else \"Unknown\"\n",
        "\n",
        "    year = \"Unknown\"\n",
        "    published = record.get(\"published-print\") or record.get(\"published-online\") or record.get(\"created\")\n",
        "    if published and \"date-parts\" in published:\n",
        "        date_parts = published[\"date-parts\"][0]\n",
        "        if date_parts:\n",
        "            year = date_parts[0]\n",
        "\n",
        "    container_title = record.get(\"container-title\", [])\n",
        "    journal = container_title[0] if container_title else \"Unknown\"\n",
        "\n",
        "    volume = record.get(\"volume\", \"-\")\n",
        "    issue = record.get(\"issue\", \"-\")\n",
        "    page = record.get(\"page\", \"-\")\n",
        "\n",
        "    doi = record.get(\"DOI\", None)\n",
        "\n",
        "    doc_type_raw = record.get(\"type\", \"unknown\")\n",
        "    doc_type_map = {\n",
        "        \"journal-article\": \"Journal Article\",\n",
        "        \"book-chapter\": \"Book Chapter\",\n",
        "        \"proceedings-article\": \"Conference Paper\",\n",
        "        \"posted-content\": \"Preprint\",\n",
        "        \"dataset\": \"Dataset\",\n",
        "        \"book\": \"Book\",\n",
        "        \"dissertation\": \"Dissertation\",\n",
        "        \"unknown\": \"Unknown\"\n",
        "    }\n",
        "    doc_type = doc_type_map.get(doc_type_raw, doc_type_raw.replace(\"-\", \" \").title())\n",
        "\n",
        "    return {\n",
        "        \"oa_full_author\": full_author_list,\n",
        "        \"oa_first_author\": first_author,\n",
        "        \"oa_title\": title,\n",
        "        \"oa_year\": year,\n",
        "        \"oa_journal\": journal,\n",
        "        \"oa_volume\": volume,\n",
        "        \"oa_issue\": issue,\n",
        "        \"oa_page_range\": normalize_page_range(page),\n",
        "        \"openalex_id\": \"N/A (Crossref)\",\n",
        "        \"oa_doi\": doi,\n",
        "        \"is_retracted\": False,\n",
        "        \"doc_type\": doc_type,\n",
        "        \"data_source\": \"Crossref\"\n",
        "    }\n",
        "\n",
        "\n",
        "def compare_metadata(parsed_ref, oa_meta):\n",
        "    diff = {}\n",
        "\n",
        "    ref_title_std = standardize_title(parsed_ref['ref_title'])\n",
        "    oa_title_std = standardize_title(oa_meta['oa_title'])\n",
        "    diff['oa_title'] = oa_meta['oa_title']\n",
        "    diff['oa_title_diff'] = ref_title_std != oa_title_std\n",
        "\n",
        "    ref_surname = extract_surname(parsed_ref['ref_first_author'])\n",
        "    oa_surname = extract_surname(oa_meta['oa_first_author'])\n",
        "    diff['oa_full_author'] = oa_meta['oa_full_author']\n",
        "    diff['oa_full_author_diff'] = ref_surname != oa_surname\n",
        "\n",
        "    ref_year = parsed_ref['ref_year']\n",
        "    oa_year = oa_meta['oa_year']\n",
        "    diff['oa_year'] = oa_year\n",
        "    if ref_year and oa_year:\n",
        "        delta = abs(ref_year - oa_year)\n",
        "        diff['oa_year_delta'] = delta\n",
        "        if delta == 0:\n",
        "            diff['oa_year_diff'] = False\n",
        "        elif delta <= 2:\n",
        "            diff['oa_year_diff'] = \"minor\"\n",
        "        else:\n",
        "            diff['oa_year_diff'] = True\n",
        "    else:\n",
        "        diff['oa_year_diff'] = True\n",
        "        diff['oa_year_delta'] = None\n",
        "\n",
        "    for key in ['journal', 'volume', 'issue', 'page_range']:\n",
        "        ref_val = str(parsed_ref[f'ref_{key}'])\n",
        "        oa_val = str(oa_meta[f'oa_{key}'])\n",
        "\n",
        "        if key == 'page_range':\n",
        "            ref_val = normalize_page_range(ref_val)\n",
        "            oa_val = normalize_page_range(oa_val)\n",
        "\n",
        "        diff[f'oa_{key}'] = oa_val\n",
        "        diff[f'oa_{key}_diff'] = ref_val != oa_val\n",
        "\n",
        "    return diff\n",
        "\n",
        "\n",
        "def verify_status(parsed_ref, oa_meta):\n",
        "    score = 0\n",
        "\n",
        "    title_score = fuzz.token_sort_ratio(\n",
        "        standardize_title(parsed_ref['ref_title']),\n",
        "        standardize_title(oa_meta['oa_title'])\n",
        "    )\n",
        "    if title_score >= 90:\n",
        "        score += 2\n",
        "    elif title_score >= 80:\n",
        "        score += 1\n",
        "\n",
        "    ref_surname = extract_surname(parsed_ref['ref_first_author'])\n",
        "    oa_surname = extract_surname(oa_meta['oa_first_author'])\n",
        "    if ref_surname and oa_surname and ref_surname == oa_surname:\n",
        "        score += 1\n",
        "\n",
        "    ref_year = parsed_ref['ref_year']\n",
        "    oa_year = oa_meta['oa_year']\n",
        "    if ref_year is not None and oa_year is not None and abs(ref_year - oa_year) <= 2:\n",
        "        score += 1\n",
        "\n",
        "    if score >= 4:\n",
        "        return \"verified\", \"high\"\n",
        "    elif score >= 2:\n",
        "        return \"ambiguous\", \"medium\"\n",
        "    else:\n",
        "        return \"unverified\", \"low\"\n",
        "\n",
        "\n",
        "def process_references(raw_references):\n",
        "    results = []\n",
        "    total = len(raw_references)\n",
        "\n",
        "    for idx, raw in enumerate(raw_references):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"[{idx + 1}/{total}] Processing:\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"{raw}\")\n",
        "        print(f\"{'-'*80}\")\n",
        "\n",
        "        parsed = parse_reference(raw)\n",
        "\n",
        "        print(f\"  üìù Parsed Information:\")\n",
        "        print(f\"     Title: {parsed['ref_title']}\")\n",
        "        print(f\"     Author: {parsed['ref_first_author']} (surname: {extract_surname(parsed['ref_first_author'])})\")\n",
        "        print(f\"     Year: {parsed['ref_year']}\")\n",
        "        print(f\"     Journal/Source: {parsed['ref_journal']}\")\n",
        "        print(f\"     Volume: {parsed['ref_volume']}, Issue: {parsed['ref_issue']}, Pages: {parsed['ref_page_range']}\")\n",
        "        print(f\"     DOI: {parsed['doi'] if parsed['doi'] else 'None'}\")\n",
        "\n",
        "        oa_record_from_doi = query_openalex_by_doi(parsed['doi'])\n",
        "        doi_lookup_success = bool(oa_record_from_doi)\n",
        "        data_source = None\n",
        "\n",
        "        if oa_record_from_doi:\n",
        "            print(f\"  ‚úì Found match via OpenAlex DOI\")\n",
        "            data_source = \"OpenAlex\"\n",
        "        elif parsed['doi']:\n",
        "            print(f\"  ‚úó DOI not found in OpenAlex\")\n",
        "            print(f\"  üîÑ Trying Crossref DOI...\")\n",
        "            crossref_record = query_crossref_by_doi(parsed['doi'])\n",
        "            if crossref_record:\n",
        "                print(f\"  ‚úì Found match via Crossref DOI\")\n",
        "                oa_record_from_doi = crossref_record\n",
        "                doi_lookup_success = True\n",
        "                data_source = \"Crossref\"\n",
        "            else:\n",
        "                print(f\"  ‚úó DOI not found in Crossref either\")\n",
        "\n",
        "        time.sleep(REQUEST_DELAY)\n",
        "\n",
        "        title_similarity_score = 0\n",
        "        if oa_record_from_doi:\n",
        "            if data_source == \"OpenAlex\":\n",
        "                oa_title_from_doi = oa_record_from_doi.get(\"title\", \"\")\n",
        "            else:\n",
        "                title_list = oa_record_from_doi.get(\"title\", [])\n",
        "                oa_title_from_doi = title_list[0] if title_list else \"\"\n",
        "\n",
        "            title_similarity_score = fuzz.token_sort_ratio(\n",
        "                standardize_title(parsed[\"ref_title\"]),\n",
        "                standardize_title(oa_title_from_doi)\n",
        "            )\n",
        "            print(f\"  üìä Title similarity ({data_source} record): {title_similarity_score}%\")\n",
        "\n",
        "        oa_record = oa_record_from_doi\n",
        "        matched_by_title = False\n",
        "\n",
        "        if not oa_record or title_similarity_score < TITLE_MISMATCH_THRESHOLD:\n",
        "            if title_similarity_score > 0 and title_similarity_score < TITLE_MISMATCH_THRESHOLD:\n",
        "                print(f\"  ‚ö†Ô∏è DOI record exists but title mismatch (similarity: {title_similarity_score}%)\")\n",
        "\n",
        "            if parsed[\"ref_title\"] == \"Unknown\":\n",
        "                print(f\"  ‚ùå Cannot search by title: Title parsing failed\")\n",
        "            else:\n",
        "                print(f\"  üîç Searching OpenAlex by title: '{parsed['ref_title'][:60]}...'\")\n",
        "                candidates = query_openalex_by_title(parsed[\"ref_title\"])\n",
        "                time.sleep(REQUEST_DELAY)\n",
        "\n",
        "                if not candidates:\n",
        "                    print(f\"  ‚úó No results from OpenAlex title search\")\n",
        "                    print(f\"  üîÑ Trying Crossref title search...\")\n",
        "                    candidates = query_crossref_by_title(parsed[\"ref_title\"])\n",
        "                    data_source = \"Crossref\" if candidates else None\n",
        "                    time.sleep(REQUEST_DELAY)\n",
        "                    if not candidates:\n",
        "                        print(f\"  ‚úó No results from Crossref title search either\")\n",
        "                else:\n",
        "                    data_source = \"OpenAlex\"\n",
        "\n",
        "                if candidates:\n",
        "                    best_score = 0\n",
        "                    best_record = None\n",
        "                    print(f\"  üìã Found {len(candidates)} candidates in {data_source}, comparing titles...\")\n",
        "\n",
        "                    for c in candidates:\n",
        "                        if data_source == \"OpenAlex\":\n",
        "                            c_title = c.get(\"title\", \"\")\n",
        "                        else:\n",
        "                            c_title_list = c.get(\"title\", [])\n",
        "                            c_title = c_title_list[0] if c_title_list else \"\"\n",
        "\n",
        "                        score = fuzz.token_sort_ratio(\n",
        "                            standardize_title(parsed[\"ref_title\"]),\n",
        "                            standardize_title(c_title)\n",
        "                        )\n",
        "                        if score > best_score:\n",
        "                            best_score = score\n",
        "                            best_record = c\n",
        "\n",
        "                    if best_score >= TITLE_THRESHOLD and best_record:\n",
        "                        oa_record = best_record\n",
        "                        matched_by_title = True\n",
        "                        print(f\"  ‚úì Found match by title in {data_source} (similarity: {best_score}%)\")\n",
        "                    else:\n",
        "                        print(f\"  ‚úó No strong title match (best similarity: {best_score}%)\")\n",
        "\n",
        "        if oa_record:\n",
        "            if data_source == \"OpenAlex\":\n",
        "                oa_meta = extract_openalex_metadata(oa_record)\n",
        "            else:\n",
        "                oa_meta = extract_crossref_metadata(oa_record)\n",
        "\n",
        "            print(f\"  üìÑ Document Type (from {data_source}): {oa_meta['doc_type']}\")\n",
        "\n",
        "            meta_diff = compare_metadata(parsed, oa_meta)\n",
        "            status, confidence = verify_status(parsed, oa_meta)\n",
        "\n",
        "            original_doi = parsed.get(\"doi\")\n",
        "            oa_doi = oa_meta.get(\"oa_doi\")\n",
        "\n",
        "            original_doi_norm = normalize_doi(original_doi)\n",
        "            oa_doi_norm = normalize_doi(oa_doi)\n",
        "\n",
        "            final_title_similarity = fuzz.token_sort_ratio(\n",
        "                standardize_title(parsed[\"ref_title\"]),\n",
        "                standardize_title(oa_meta[\"oa_title\"])\n",
        "            )\n",
        "\n",
        "            if original_doi:\n",
        "                if doi_lookup_success and final_title_similarity < TITLE_MISMATCH_THRESHOLD:\n",
        "                    filled_doi = None\n",
        "                    doi_fill_status = \"doi_title_mismatch\"\n",
        "                    print(f\"  ‚ùå DOI-Title mismatch (similarity: {final_title_similarity}%)\")\n",
        "                elif oa_doi_norm and original_doi_norm == oa_doi_norm and final_title_similarity >= TITLE_MISMATCH_THRESHOLD:\n",
        "                    filled_doi = original_doi\n",
        "                    doi_fill_status = \"original_correct\"\n",
        "                    print(f\"  ‚úì DOI verified: {original_doi}\")\n",
        "                elif matched_by_title and oa_doi:\n",
        "                    filled_doi = oa_doi\n",
        "                    doi_fill_status = \"title_matched_doi_corrected\"\n",
        "                    print(f\"  üîß Matched by title, DOI corrected: {original_doi} ‚Üí {oa_doi}\")\n",
        "                elif oa_doi and original_doi_norm != oa_doi_norm:\n",
        "                    filled_doi = oa_doi\n",
        "                    doi_fill_status = \"original_wrong_corrected\"\n",
        "                    print(f\"  ‚ö†Ô∏è DOI mismatch! Original: {original_doi} ‚Üí Corrected: {oa_doi}\")\n",
        "                else:\n",
        "                    filled_doi = original_doi\n",
        "                    doi_fill_status = \"original_unverified\"\n",
        "            elif oa_doi:\n",
        "                filled_doi = oa_doi\n",
        "                doi_fill_status = \"filled_from_database\"\n",
        "                print(f\"  ‚ûï DOI added from {data_source}: {oa_doi}\")\n",
        "            else:\n",
        "                filled_doi = None\n",
        "                doi_fill_status = \"missing\"\n",
        "\n",
        "            is_retracted = oa_meta.get('is_retracted', False)\n",
        "        else:\n",
        "            oa_meta = {\n",
        "                k: \"Unknown\" for k in [\n",
        "                    \"oa_title\", \"oa_first_author\", \"oa_year\", \"oa_journal\",\n",
        "                    \"oa_volume\", \"oa_issue\", \"oa_page_range\", \"openalex_id\", \"oa_doi\"\n",
        "                ]\n",
        "            }\n",
        "            oa_meta['is_retracted'] = False\n",
        "            oa_meta['data_source'] = \"None\"\n",
        "            oa_meta['doc_type'] = \"Unknown\"\n",
        "            meta_diff = {\n",
        "                f\"{k}_diff\": False for k in [\n",
        "                    \"oa_title\", \"oa_first_author\", \"oa_year\", \"oa_journal\",\n",
        "                    \"oa_volume\", \"oa_issue\", \"oa_page_range\", \"openalex_id\", \"oa_doi\"\n",
        "                ]\n",
        "            }\n",
        "            meta_diff['oa_year_diff'] = True\n",
        "            meta_diff['oa_year_delta'] = None\n",
        "            status, confidence = \"unverified\", \"unverified\"\n",
        "            is_retracted = False\n",
        "\n",
        "            original_doi = parsed.get(\"doi\")\n",
        "            if original_doi:\n",
        "                filled_doi = None\n",
        "                doi_fill_status = \"unverified\"\n",
        "                print(f\"  ‚ùå DOI unverified (not found in OpenAlex or Crossref)\")\n",
        "            else:\n",
        "                filled_doi = None\n",
        "                doi_fill_status = \"missing\"\n",
        "                print(f\"  ‚ùì No DOI provided and no match found\")\n",
        "\n",
        "        result = {\n",
        "            **parsed,\n",
        "            **oa_meta,\n",
        "            **meta_diff,\n",
        "            \"filled_doi\": filled_doi,\n",
        "            \"doi_fill_status\": doi_fill_status,\n",
        "            \"status\": status,\n",
        "            \"confidence\": confidence\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def generate_html_table(df):\n",
        "    def get_cell_style(row, col):\n",
        "        if col == \"doc_type\":\n",
        "            doc_type = str(row['doc_type'])\n",
        "            if doc_type == \"Journal Article\":\n",
        "                return 'color: #1976D2; font-weight: bold'\n",
        "            elif doc_type == \"Conference Paper\":\n",
        "                return 'color: #FF6F00; font-weight: bold'\n",
        "            elif doc_type == \"Book Chapter\":\n",
        "                return 'color: #7B1FA2; font-weight: bold'\n",
        "            elif doc_type == \"Preprint\":\n",
        "                return 'color: #00897B; font-weight: bold'\n",
        "\n",
        "        if col == \"data_source\":\n",
        "            source = str(row['data_source'])\n",
        "            if source == \"OpenAlex\":\n",
        "                return 'color: #1976D2; font-weight: bold'\n",
        "            elif source == \"Crossref\":\n",
        "                return 'color: #FF6F00; font-weight: bold'\n",
        "            elif source == \"None\":\n",
        "                return 'color: gray'\n",
        "\n",
        "        if col == \"is_retracted\":\n",
        "            if row['is_retracted'] == True:\n",
        "                return 'background-color: #D32F2F; color: white; font-weight: bold'\n",
        "            else:\n",
        "                return 'color: green'\n",
        "\n",
        "        elif col == \"doi_fill_status\":\n",
        "            status = str(row['doi_fill_status'])\n",
        "            if status == \"original_correct\":\n",
        "                return 'color: green; font-weight: bold'\n",
        "            elif status == \"filled_from_database\":\n",
        "                return 'color: blue; font-weight: bold'\n",
        "            elif status == \"title_matched_doi_corrected\":\n",
        "                return 'color: #1976D2; font-weight: bold'\n",
        "            elif status == \"original_wrong_corrected\":\n",
        "                return 'background-color: #FFA726; color: white; font-weight: bold'\n",
        "            elif status == \"doi_title_mismatch\":\n",
        "                return 'background-color: #E91E63; color: white; font-weight: bold'\n",
        "            elif status == \"unverified\":\n",
        "                return 'color: red; font-weight: bold'\n",
        "            elif status == \"missing\":\n",
        "                return 'color: gray'\n",
        "\n",
        "        elif col == \"filled_doi\":\n",
        "            status = str(row['doi_fill_status'])\n",
        "            if status == \"filled_from_database\":\n",
        "                return 'color: blue; font-weight: bold'\n",
        "            elif status == \"title_matched_doi_corrected\":\n",
        "                return 'color: #1976D2; font-weight: bold'\n",
        "            elif status == \"original_wrong_corrected\":\n",
        "                return 'color: orange; font-weight: bold'\n",
        "            elif status in [\"unverified\", \"doi_title_mismatch\"]:\n",
        "                return 'color: red; font-weight: bold'\n",
        "\n",
        "        elif col == \"doi\":\n",
        "            if row['doi_fill_status'] in [\"unverified\", \"doi_title_mismatch\"]:\n",
        "                return 'color: red; font-weight: bold'\n",
        "\n",
        "        elif col == \"oa_year\":\n",
        "            if row['oa_year_diff'] == False:\n",
        "                return 'color: green'\n",
        "            elif row['oa_year_diff'] == \"minor\":\n",
        "                return 'background-color: yellow'\n",
        "            elif row['oa_year_diff'] == True:\n",
        "                return 'color: red'\n",
        "\n",
        "        elif row['status'] == 'verified' and col.startswith('oa'):\n",
        "            return 'color: green'\n",
        "\n",
        "        elif row['status'] == 'unverified' and col.startswith('oa'):\n",
        "            return 'color: red'\n",
        "\n",
        "        elif col in [\"oa_title\", \"oa_full_author\", \"oa_journal\", \"oa_volume\", \"oa_issue\", \"oa_page_range\"] and row.get(f\"{col}_diff\", False):\n",
        "            return 'color: red'\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    html = \"\"\"\n",
        "    <style>\n",
        "        table { border-collapse: collapse; width: 100%; font-size: 11px; }\n",
        "        th { background-color: #1976D2; color: white; padding: 8px; text-align: left; position: sticky; top: 0; z-index: 10; }\n",
        "        td { padding: 6px; border: 1px solid #ddd; word-wrap: break-word; max-width: 300px; }\n",
        "        tr:nth-child(even) { background-color: #f9f9f9; }\n",
        "        tr:hover { background-color: #f5f5f5; }\n",
        "        .container { max-height: 600px; overflow: auto; }\n",
        "    </style>\n",
        "    <div class=\"container\">\n",
        "    <table>\n",
        "        <thead><tr>\n",
        "    \"\"\"\n",
        "\n",
        "    for col in df.columns:\n",
        "        html += f\"<th>{col}</th>\"\n",
        "    html += \"</tr></thead><tbody>\"\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        html += \"<tr>\"\n",
        "        for col in df.columns:\n",
        "            style = get_cell_style(row, col)\n",
        "            value = row[col]\n",
        "            if pd.isna(value):\n",
        "                value = \"-\"\n",
        "            html += f'<td style=\"{style}\">{value}</td>'\n",
        "        html += \"</tr>\"\n",
        "\n",
        "    html += \"</tbody></table></div>\"\n",
        "    return html\n",
        "\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üìö LLM-Generated Reference Verification Tool - Interactive Version\")\n",
        "print(\"   \")\n",
        "print(\"   Usage:\")\n",
        "print(\"   1. Run this cell\")\n",
        "print(\"   2. Paste references into the text box\")\n",
        "print(\"   3. Click Run Verification button\")\n",
        "print(\"   4. View results with color highlighting\")\n",
        "print(\"   \")\n",
        "print(\"   Supports: APA, Harvard, Chicago, IEEE, ACM, MLA\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n‚ö†Ô∏è  IMPORTANT: Replace email in HEADERS!\")\n",
        "print(\"   \")\n",
        "print(\"\\nüìÑ  Paste references below (one per line)\\n\")\n",
        "\n",
        "\n",
        "text_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Paste references...\\n\\nExample:\\nCortes, C., & Vapnik, V. (1995). Support-vector Networks. Machine Learning, 20(3), 273‚Äì297. \\nHinton, G. E., Osindero, S., & Teh, Y. (2006). A fast learning algorithm for deep belief nets. Neural Computation, 18(7), 1527‚Äì1554. https://doi.org/10.1162/neco.2006.18.7.1527',\n",
        "    description='References:',\n",
        "    layout=widgets.Layout(width='95%', height='300px'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "run_button = widgets.Button(\n",
        "    description='üöÄ Run Verification',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='200px', height='40px')\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_button_click(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        content = text_input.value.strip()\n",
        "        if not content:\n",
        "            print(\"‚ùå Please enter at least one reference.\")\n",
        "            return\n",
        "\n",
        "        references = [line.strip() for line in content.split('\\n') if line.strip()]\n",
        "        print(f\"\\n‚úì Loaded {len(references)} references\\n\")\n",
        "\n",
        "        results = process_references(references)\n",
        "        df = pd.DataFrame(results)\n",
        "\n",
        "        status_icon_map = {\"verified\": \"‚úÖ\", \"ambiguous\": \"‚ö†Ô∏è\", \"unverified\": \"‚ùå\"}\n",
        "        df['status_icon'] = df['status'].map(status_icon_map)\n",
        "\n",
        "        front_cols = [\"status\", \"confidence\", \"status_icon\", \"is_retracted\", \"doc_type\", \"data_source\"]\n",
        "        doi_cols = [\"doi\", \"filled_doi\", \"doi_fill_status\"]\n",
        "        other_cols = [c for c in df.columns if c not in front_cols + doi_cols + [\"oa_first_author_diff\", \"openalex_id_diff\"]]\n",
        "        df = df[front_cols + doi_cols + other_cols]\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"üìä Verification Statistics\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        verified_count = len(df[df['status'] == 'verified'])\n",
        "        ambiguous_count = len(df[df['status'] == 'ambiguous'])\n",
        "        unverified_count = len(df[df['status'] == 'unverified'])\n",
        "        retracted_count = len(df[df['is_retracted'] == True])\n",
        "\n",
        "        journal_count = len(df[df['doc_type'] == 'Journal Article'])\n",
        "        conf_count = len(df[df['doc_type'] == 'Conference Paper'])\n",
        "        book_count = len(df[df['doc_type'] == 'Book Chapter'])\n",
        "        other_doc_count = len(df) - journal_count - conf_count - book_count\n",
        "\n",
        "        openalex_count = len(df[df['data_source'] == 'OpenAlex'])\n",
        "        crossref_count = len(df[df['data_source'] == 'Crossref'])\n",
        "        none_count = len(df[df['data_source'] == 'None'])\n",
        "\n",
        "        print(f\"Total references: {len(df)}\")\n",
        "        print(f\"‚úÖ Verified: {verified_count} ({verified_count/len(df)*100:.1f}%)\")\n",
        "        print(f\"‚ö†Ô∏è  Ambiguous: {ambiguous_count} ({ambiguous_count/len(df)*100:.1f}%)\")\n",
        "        print(f\"‚ùå Unverified: {unverified_count} ({unverified_count/len(df)*100:.1f}%)\")\n",
        "        print(f\"üö® Retracted: {retracted_count}\")\n",
        "\n",
        "        print(f\"\\nüìÑ Document Types (from database):\")\n",
        "        print(f\"  üìò Journal Articles: {journal_count}\")\n",
        "        print(f\"  üìô Conference Papers: {conf_count}\")\n",
        "        print(f\"  üìï Book Chapters: {book_count}\")\n",
        "        if other_doc_count > 0:\n",
        "            print(f\"  üìó Other: {other_doc_count}\")\n",
        "\n",
        "        print(f\"\\nüóÑÔ∏è Data Sources:\")\n",
        "        print(f\"  üìò OpenAlex: {openalex_count}\")\n",
        "        print(f\"  üìô Crossref: {crossref_count}\")\n",
        "        print(f\"  ‚ùå Not found: {none_count}\")\n",
        "\n",
        "        doi_correct = len(df[df['doi_fill_status'] == 'original_correct'])\n",
        "        doi_filled = len(df[df['doi_fill_status'] == 'filled_from_database'])\n",
        "        doi_corrected = len(df[df['doi_fill_status'] == 'original_wrong_corrected'])\n",
        "        doi_title_corrected = len(df[df['doi_fill_status'] == 'title_matched_doi_corrected'])\n",
        "        doi_title_mismatch = len(df[df['doi_fill_status'] == 'doi_title_mismatch'])\n",
        "        doi_unverified = len(df[df['doi_fill_status'] == 'unverified'])\n",
        "        doi_missing = len(df[df['doi_fill_status'] == 'missing'])\n",
        "\n",
        "        print(f\"\\nüìã DOI Status:\")\n",
        "        print(f\"  ‚úì Original correct: {doi_correct}\")\n",
        "        print(f\"  ‚ûï Filled from database: {doi_filled}\")\n",
        "        print(f\"  üîß Corrected (wrong original): {doi_corrected}\")\n",
        "        print(f\"  üîÑ Title matched, DOI corrected: {doi_title_corrected}\")\n",
        "        print(f\"  ‚ö†Ô∏è  DOI-Title mismatch: {doi_title_mismatch}\")\n",
        "        print(f\"  ‚ùå Unverified: {doi_unverified}\")\n",
        "        print(f\"  ‚ùì Missing: {doi_missing}\")\n",
        "\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(\"\\nüìã Detailed Results (with color highlighting):\\n\")\n",
        "        html_table = generate_html_table(df)\n",
        "        display(HTML(html_table))\n",
        "\n",
        "        print(\"\\n‚úÖ Processing complete!\")\n",
        "        print(\"\\nüíæ To export results, use: df.to_csv('verification_results.csv', index=False)\")\n",
        "\n",
        "run_button.on_click(on_button_click)\n",
        "\n",
        "display(text_input)\n",
        "display(run_button)\n",
        "display(output)\n"
      ]
    }
  ]
}